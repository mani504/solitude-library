import keras_ocr
import cv2
import os
import numpy as np

# Function to perform inpainting using OpenCV
def inpaint_text(image, boxes):
    mask = np.zeros(image.shape[:2], dtype=np.uint8)  # Mask to mark the text regions
    for box in boxes:
        # Extract the box coordinates
        box = np.array(box).astype(int)
        # Draw filled polygon (text bounding box) on the mask
        cv2.fillPoly(mask, [box], 255)
    
    # Inpaint the image using Telea algorithm (or you can experiment with Navier-Stokes)
    inpainted_image = cv2.inpaint(image, mask, inpaintRadius=3, flags=cv2.INPAINT_TELEA)
    return inpainted_image

# Function to process images in a directory
def remove_text_from_images(input_dir, output_dir):
    # Initialize the Keras-OCR pipeline
    pipeline = keras_ocr.pipeline.Pipeline()

    # Ensure output directory exists
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # Process each image in the input directory
    for image_name in os.listdir(input_dir):
        if image_name.endswith(('png', 'jpg', 'jpeg')):
            # Read the image
            image_path = os.path.join(input_dir, image_name)
            image = keras_ocr.tools.read(image_path)

            # Perform text detection
            prediction_groups = pipeline.recognize([image])
            boxes = [box for box, text in prediction_groups[0]]

            # Perform inpainting at the character level
            inpainted_image = inpaint_text(image, boxes)

            # Save the output image
            output_path = os.path.join(output_dir, image_name)
            cv2.imwrite(output_path, inpainted_image)

# Example usage
input_directory = 'path_to_input_directory'
output_directory = 'path_to_output_directory'

remove_text_from_images(input_directory, output_directory)












import keras_ocr
import cv2
import os
import numpy as np

# Function to perform inpainting using OpenCV
def inpaint_text(image, boxes):
    mask = np.zeros(image.shape[:2], dtype=np.uint8)  # Mask to mark the text regions
    for box in boxes:
        # Convert bounding box to integer
        box = np.array(box).astype(np.int32)

        # Draw a filled rectangle over the text area using the bounding box
        # Keras OCR gives boxes in the form of a quadrilateral, so we take the top-left and bottom-right points
        top_left = (box[0][0], box[0][1])
        bottom_right = (box[2][0], box[2][1])

        # Draw a filled rectangle on the mask
        cv2.rectangle(mask, top_left, bottom_right, 255, thickness=-1)

    # Inpaint the image using the mask
    inpainted_image = cv2.inpaint(image, mask, inpaintRadius=3, flags=cv2.INPAINT_TELEA)
    return inpainted_image

# Function to process images in a directory
def remove_text_from_images(input_dir, output_dir):
    # Initialize the Keras-OCR pipeline
    pipeline = keras_ocr.pipeline.Pipeline()

    # Ensure output directory exists
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # Process each image in the input directory
    for image_name in os.listdir(input_dir):
        if image_name.endswith(('png', 'jpg', 'jpeg')):
            # Read the image
            image_path = os.path.join(input_dir, image_name)
            image = keras_ocr.tools.read(image_path)

            # Perform text detection
            prediction_groups = pipeline.recognize([image])
            boxes = [box for box, text in prediction_groups[0]]

            # Perform inpainting at the character level
            inpainted_image = inpaint_text(image, boxes)

            # Save the output image
            output_path = os.path.join(output_dir, image_name)
            cv2.imwrite(output_path, inpainted_image)

# Example usage
input_directory = 'path_to_input_directory'
output_directory = 'path_to_output_directory'

remove_text_from_images(input_directory, output_directory)










import keras_ocr
import cv2
import os
import numpy as np
from concurrent.futures import ThreadPoolExecutor

# Initialize the Keras-OCR pipeline once
pipeline = keras_ocr.pipeline.Pipeline()

# Function to perform inpainting using OpenCV
def inpaint_text(image, boxes):
    h, w = image.shape[:2]
    mask = np.zeros((h, w), dtype=np.uint8)  # Mask to mark the text regions
    for box in boxes:
        # Convert bounding box to integer
        box = np.array(box).astype(np.int32)

        # Calculate top-left and bottom-right corners from quadrilateral
        top_left = (min(box[:, 0]), min(box[:, 1]))
        bottom_right = (max(box[:, 0]), max(box[:, 1]))

        # Draw filled rectangle on the mask
        cv2.rectangle(mask, top_left, bottom_right, 255, thickness=-1)

    # Inpaint the image using the generated mask
    return cv2.inpaint(image, mask, inpaintRadius=3, flags=cv2.INPAINT_TELEA)

# Function to process a single image
def process_image(image_path, output_path):
    # Read the image
    image = keras_ocr.tools.read(image_path)

    # Perform text detection using the pre-loaded pipeline
    prediction_groups = pipeline.recognize([image])
    boxes = [box for box, text in prediction_groups[0]]

    # Perform inpainting
    inpainted_image = inpaint_text(image, boxes)

    # Save the inpainted image
    cv2.imwrite(output_path, inpainted_image)

# Function to process images in a directory with multi-threading for efficiency
def remove_text_from_images(input_dir, output_dir, num_threads=4):
    # Ensure the output directory exists
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # List of all images in the input directory
    image_files = [f for f in os.listdir(input_dir) if f.endswith(('png', 'jpg', 'jpeg'))]

    # Multi-threaded processing of images
    with ThreadPoolExecutor(max_workers=num_threads) as executor:
        futures = []
        for image_name in image_files:
            input_image_path = os.path.join(input_dir, image_name)
            output_image_path = os.path.join(output_dir, image_name)
            futures.append(executor.submit(process_image, input_image_path, output_image_path))

        # Wait for all threads to complete
        for future in futures:
            future.result()

# Example usage
input_directory = 'path_to_input_directory'
output_directory = 'path_to_output_directory'

remove_text_from_images(input_directory, output_directory, num_threads=8)









import cv2
import numpy as np
import os
import keras_ocr

# Function to detect and inpaint characters
def inpaint_text_by_character(img, predictions):
    # Create a mask for inpainting
    mask = np.zeros(img.shape[:2], dtype="uint8")

    # Iterate through detected words and create a mask
    for word, box in predictions:
        # Get the bounding box of the word
        x_min = int(min([point[0] for point in box]))
        y_min = int(min([point[1] for point in box]))
        x_max = int(max([point[0] for point in box]))
        y_max = int(max([point[1] for point in box]))
        
        # Create the mask for inpainting (character-level)
        cv2.rectangle(mask, (x_min, y_min), (x_max, y_max), 255, -1)

    # Inpaint the masked text regions using cv2.INPAINT_TELEA
    inpainted_img = cv2.inpaint(img, mask, 7, cv2.INPAINT_TELEA)

    # Post-processing to remove leftover dots or artifacts
    kernel = np.ones((3, 3), np.uint8)
    inpainted_img = cv2.morphologyEx(inpainted_img, cv2.MORPH_CLOSE, kernel)  # Dilation followed by erosion

    return inpainted_img

# Function to process all images in a directory
def process_images(input_dir, output_dir, pipeline):
    # Create output directory if it doesn't exist
    os.makedirs(output_dir, exist_ok=True)
    
    # Get list of all images in the input directory
    image_filenames = [f for f in os.listdir(input_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
    
    if not image_filenames:
        print("No image files found in the input directory.")
        return
    
    # Prepare the images for batch processing
    image_paths = [os.path.join(input_dir, fname) for fname in image_filenames]
    images = [keras_ocr.tools.read(img_path) for img_path in image_paths]

    # Detect text in all images at once using the Keras OCR pipeline
    prediction_groups = pipeline.recognize(images)

    # Process each image and save the inpainted result
    for img, predictions, filename in zip(images, prediction_groups, image_filenames):
        inpainted_img = inpaint_text_by_character(img, predictions)
        
        # Save the final image
        output_path = os.path.join(output_dir, filename)
        cv2.imwrite(output_path, cv2.cvtColor(inpainted_img, cv2.COLOR_RGB2BGR))  # Save in BGR format for OpenCV compatibility

    print(f"Processing complete. Output images saved in '{output_dir}' directory.")

# Main function to run the script
def main():
    input_dir = 'input'
    output_dir = 'outputTess'

    # Initialize Keras OCR pipeline once
    pipeline = keras_ocr.pipeline.Pipeline()

    # Process all images in the input directory
    process_images(input_dir, output_dir, pipeline)

# Run the script
if __name__ == "__main__":
    main()





















Here's a sample `README.md` update that describes how to run your script while keeping the input and output directories defined in the code:

---

# Image Inpainting with Keras OCR

This script detects and inpaints text characters in images using Keras OCR.

## Requirements

Ensure you have the following libraries installed:

- OpenCV
- NumPy
- Keras OCR

You can install the required libraries using the `requirements.txt` file:

```bash
pip install -r requirements.txt
```

## Usage

To run the script, use the following command in your terminal:

```bash
python script_name.py
```

**Note**: The script is set to read images from a predefined input directory (`input`) and will save the output images to a predefined output directory (`outputTess`). You can modify these directories in the code if needed.

## Input Directory Structure

Make sure you have an `input` directory in the same location as your script, containing the images you want to process. The script supports the following image formats:

- PNG
- JPG
- JPEG

## Output

The processed images will be saved in the `outputTess` directory after running the script.

---

Feel free to modify any parts of the `README.md` to better suit your project's style!






The script constructs a binary mask by drawing rectangles around the bounding boxes of the individual 
characters. This mask is then used in the inpainting process, where the OpenCV inpainting function replaces the masked areas with neighboring pixel information, effectively "painting over" the detected characters to remove them from the image.






import json
import sys
from PIL import Image, ImageDraw

def draw_rectangles(json_path, output_path):
    # Step 1: Read the JSON file
    with open(json_path, 'r') as f:
        data = json.load(f)
    
    # Step 2: Create a blank image (let's assume a default size like 500x500)
    img_width, img_height = 500, 500
    img = Image.new('RGB', (img_width, img_height), color='white')
    draw = ImageDraw.Draw(img)
    
    # Step 3: Loop through rectangles and draw them
    for rect in data.get('rectangles', []):
        x, y = rect['x'], rect['y']
        width, height = rect['width'], rect['height']
        draw.rectangle([x, y, x + width, y + height], outline='black', width=2)
    
    # Step 4: Save the image to the output path
    img.save(output_path)
    print(f"Image saved to {output_path}")

if __name__ == "__main__":
    # Command-line arguments: json file and output path
    if len(sys.argv) != 3:
        print("Usage: python script.py <json_file> <output_image_path>")
        sys.exit(1)

    json_file = sys.argv[1]
    output_image_path = sys.argv[2]
    
    # Call the function to draw rectangles and save the image
    draw_rectangles(json_file, output_image_path)







import json
import sys
from PIL import Image, ImageDraw

def draw_shapes(json_path, output_path):
    # Step 1: Read the JSON file
    with open(json_path, 'r') as f:
        data = json.load(f)

    # Step 2: Create a blank image (let's assume a default size like 500x500)
    img_width, img_height = 500, 500
    img = Image.new('RGB', (img_width, img_height), color='white')
    draw = ImageDraw.Draw(img)
    
    # Step 3: Loop through each shape in the JSON
    for shape in data.get('shapes', []):
        shape_type = shape.get('shape_type')
        points = shape.get('points')
        color = shape.get('shape_color', '#000000')  # Default color is black
        flag = shape.get('flag', True)  # Default flag is True

        if not flag:
            # Skip shapes where the flag is False
            continue
        
        # Step 4: Handle different shape types
        if shape_type == "rectangle":
            # For rectangles, the points should contain two points: top-left and bottom-right
            if len(points) == 2:
                top_left = points[0]
                bottom_right = points[1]
                draw.rectangle([top_left, bottom_right], outline=color, width=2)
        
        elif shape_type == "polygon":
            # For polygons, the points contain multiple coordinates
            if len(points) > 2:
                draw.polygon(points, outline=color)
        
        # You can add more shapes here if needed (e.g., circle, ellipse, etc.)
    
    # Step 5: Save the image to the output path
    img.save(output_path)
    print(f"Image saved to {output_path}")

if __name__ == "__main__":
    # Command-line arguments: json file and output path
    if len(sys.argv) != 3:
        print("Usage: python script.py <json_file> <output_image_path>")
        sys.exit(1)

    json_file = sys.argv[1]
    output_image_path = sys.argv[2]
    
    # Call the function to draw shapes and save the image
    draw_shapes(json_file, output_image_path)

