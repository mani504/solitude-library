import keras_ocr
import cv2
import os
import numpy as np

# Function to perform inpainting using OpenCV
def inpaint_text(image, boxes):
    mask = np.zeros(image.shape[:2], dtype=np.uint8)  # Mask to mark the text regions
    for box in boxes:
        # Extract the box coordinates
        box = np.array(box).astype(int)
        # Draw filled polygon (text bounding box) on the mask
        cv2.fillPoly(mask, [box], 255)
    
    # Inpaint the image using Telea algorithm (or you can experiment with Navier-Stokes)
    inpainted_image = cv2.inpaint(image, mask, inpaintRadius=3, flags=cv2.INPAINT_TELEA)
    return inpainted_image

# Function to process images in a directory
def remove_text_from_images(input_dir, output_dir):
    # Initialize the Keras-OCR pipeline
    pipeline = keras_ocr.pipeline.Pipeline()

    # Ensure output directory exists
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # Process each image in the input directory
    for image_name in os.listdir(input_dir):
        if image_name.endswith(('png', 'jpg', 'jpeg')):
            # Read the image
            image_path = os.path.join(input_dir, image_name)
            image = keras_ocr.tools.read(image_path)

            # Perform text detection
            prediction_groups = pipeline.recognize([image])
            boxes = [box for box, text in prediction_groups[0]]

            # Perform inpainting at the character level
            inpainted_image = inpaint_text(image, boxes)

            # Save the output image
            output_path = os.path.join(output_dir, image_name)
            cv2.imwrite(output_path, inpainted_image)

# Example usage
input_directory = 'path_to_input_directory'
output_directory = 'path_to_output_directory'

remove_text_from_images(input_directory, output_directory)












import keras_ocr
import cv2
import os
import numpy as np

# Function to perform inpainting using OpenCV
def inpaint_text(image, boxes):
    mask = np.zeros(image.shape[:2], dtype=np.uint8)  # Mask to mark the text regions
    for box in boxes:
        # Convert bounding box to integer
        box = np.array(box).astype(np.int32)

        # Draw a filled rectangle over the text area using the bounding box
        # Keras OCR gives boxes in the form of a quadrilateral, so we take the top-left and bottom-right points
        top_left = (box[0][0], box[0][1])
        bottom_right = (box[2][0], box[2][1])

        # Draw a filled rectangle on the mask
        cv2.rectangle(mask, top_left, bottom_right, 255, thickness=-1)

    # Inpaint the image using the mask
    inpainted_image = cv2.inpaint(image, mask, inpaintRadius=3, flags=cv2.INPAINT_TELEA)
    return inpainted_image

# Function to process images in a directory
def remove_text_from_images(input_dir, output_dir):
    # Initialize the Keras-OCR pipeline
    pipeline = keras_ocr.pipeline.Pipeline()

    # Ensure output directory exists
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # Process each image in the input directory
    for image_name in os.listdir(input_dir):
        if image_name.endswith(('png', 'jpg', 'jpeg')):
            # Read the image
            image_path = os.path.join(input_dir, image_name)
            image = keras_ocr.tools.read(image_path)

            # Perform text detection
            prediction_groups = pipeline.recognize([image])
            boxes = [box for box, text in prediction_groups[0]]

            # Perform inpainting at the character level
            inpainted_image = inpaint_text(image, boxes)

            # Save the output image
            output_path = os.path.join(output_dir, image_name)
            cv2.imwrite(output_path, inpainted_image)

# Example usage
input_directory = 'path_to_input_directory'
output_directory = 'path_to_output_directory'

remove_text_from_images(input_directory, output_directory)










import keras_ocr
import cv2
import os
import numpy as np
from concurrent.futures import ThreadPoolExecutor

# Initialize the Keras-OCR pipeline once
pipeline = keras_ocr.pipeline.Pipeline()

# Function to perform inpainting using OpenCV
def inpaint_text(image, boxes):
    h, w = image.shape[:2]
    mask = np.zeros((h, w), dtype=np.uint8)  # Mask to mark the text regions
    for box in boxes:
        # Convert bounding box to integer
        box = np.array(box).astype(np.int32)

        # Calculate top-left and bottom-right corners from quadrilateral
        top_left = (min(box[:, 0]), min(box[:, 1]))
        bottom_right = (max(box[:, 0]), max(box[:, 1]))

        # Draw filled rectangle on the mask
        cv2.rectangle(mask, top_left, bottom_right, 255, thickness=-1)

    # Inpaint the image using the generated mask
    return cv2.inpaint(image, mask, inpaintRadius=3, flags=cv2.INPAINT_TELEA)

# Function to process a single image
def process_image(image_path, output_path):
    # Read the image
    image = keras_ocr.tools.read(image_path)

    # Perform text detection using the pre-loaded pipeline
    prediction_groups = pipeline.recognize([image])
    boxes = [box for box, text in prediction_groups[0]]

    # Perform inpainting
    inpainted_image = inpaint_text(image, boxes)

    # Save the inpainted image
    cv2.imwrite(output_path, inpainted_image)

# Function to process images in a directory with multi-threading for efficiency
def remove_text_from_images(input_dir, output_dir, num_threads=4):
    # Ensure the output directory exists
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # List of all images in the input directory
    image_files = [f for f in os.listdir(input_dir) if f.endswith(('png', 'jpg', 'jpeg'))]

    # Multi-threaded processing of images
    with ThreadPoolExecutor(max_workers=num_threads) as executor:
        futures = []
        for image_name in image_files:
            input_image_path = os.path.join(input_dir, image_name)
            output_image_path = os.path.join(output_dir, image_name)
            futures.append(executor.submit(process_image, input_image_path, output_image_path))

        # Wait for all threads to complete
        for future in futures:
            future.result()

# Example usage
input_directory = 'path_to_input_directory'
output_directory = 'path_to_output_directory'

remove_text_from_images(input_directory, output_directory, num_threads=8)









import cv2
import numpy as np
import os
import keras_ocr

# Function to detect and inpaint characters
def inpaint_text_by_character(img, predictions):
    # Create a mask for inpainting
    mask = np.zeros(img.shape[:2], dtype="uint8")

    # Iterate through detected words and create a mask
    for word, box in predictions:
        # Get the bounding box of the word
        x_min = int(min([point[0] for point in box]))
        y_min = int(min([point[1] for point in box]))
        x_max = int(max([point[0] for point in box]))
        y_max = int(max([point[1] for point in box]))
        
        # Create the mask for inpainting (character-level)
        cv2.rectangle(mask, (x_min, y_min), (x_max, y_max), 255, -1)

    # Inpaint the masked text regions using cv2.INPAINT_TELEA
    inpainted_img = cv2.inpaint(img, mask, 7, cv2.INPAINT_TELEA)

    # Post-processing to remove leftover dots or artifacts
    kernel = np.ones((3, 3), np.uint8)
    inpainted_img = cv2.morphologyEx(inpainted_img, cv2.MORPH_CLOSE, kernel)  # Dilation followed by erosion

    return inpainted_img

# Function to process all images in a directory
def process_images(input_dir, output_dir, pipeline):
    # Create output directory if it doesn't exist
    os.makedirs(output_dir, exist_ok=True)
    
    # Get list of all images in the input directory
    image_filenames = [f for f in os.listdir(input_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
    
    if not image_filenames:
        print("No image files found in the input directory.")
        return
    
    # Prepare the images for batch processing
    image_paths = [os.path.join(input_dir, fname) for fname in image_filenames]
    images = [keras_ocr.tools.read(img_path) for img_path in image_paths]

    # Detect text in all images at once using the Keras OCR pipeline
    prediction_groups = pipeline.recognize(images)

    # Process each image and save the inpainted result
    for img, predictions, filename in zip(images, prediction_groups, image_filenames):
        inpainted_img = inpaint_text_by_character(img, predictions)
        
        # Save the final image
        output_path = os.path.join(output_dir, filename)
        cv2.imwrite(output_path, cv2.cvtColor(inpainted_img, cv2.COLOR_RGB2BGR))  # Save in BGR format for OpenCV compatibility

    print(f"Processing complete. Output images saved in '{output_dir}' directory.")

# Main function to run the script
def main():
    input_dir = 'input'
    output_dir = 'outputTess'

    # Initialize Keras OCR pipeline once
    pipeline = keras_ocr.pipeline.Pipeline()

    # Process all images in the input directory
    process_images(input_dir, output_dir, pipeline)

# Run the script
if __name__ == "__main__":
    main()





















Here's a sample `README.md` update that describes how to run your script while keeping the input and output directories defined in the code:

---

# Image Inpainting with Keras OCR

This script detects and inpaints text characters in images using Keras OCR.

## Requirements

Ensure you have the following libraries installed:

- OpenCV
- NumPy
- Keras OCR

You can install the required libraries using the `requirements.txt` file:

```bash
pip install -r requirements.txt
```

## Usage

To run the script, use the following command in your terminal:

```bash
python script_name.py
```

**Note**: The script is set to read images from a predefined input directory (`input`) and will save the output images to a predefined output directory (`outputTess`). You can modify these directories in the code if needed.

## Input Directory Structure

Make sure you have an `input` directory in the same location as your script, containing the images you want to process. The script supports the following image formats:

- PNG
- JPG
- JPEG

## Output

The processed images will be saved in the `outputTess` directory after running the script.

---

Feel free to modify any parts of the `README.md` to better suit your project's style!










